{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "David Giacobbi  \n",
    "Gonzaga University  \n",
    "CPSC 222, Spring 2022\n",
    "\n",
    "# Exploratory Data Analysis: Apple Watch Fitness Data\n",
    "\n",
    "## Introduction\n",
    "\n",
    "During my first year of college, fitness has been a critical aspect of my daily life and routine. In a place where nearly everything is in walking distance and I have the free time to workout on an ordered schedule, I realized fitness has a large impact on my daily habits. Moreover, I recently got an Apple Watch over Christmas break, so a detailed and accurate analysis of my fitness data was accessible for the Spring 2022 semester.\n",
    "\n",
    "Fitness data is a large spectrum, so I wanted to focus my project specifically on how certain day attributes affect health and workout activity. Visualizing and testing trends could help answer a few of the following questions:\n",
    "\n",
    "* Does the type of weather affect the amount I workout?\n",
    "* Is my workout intensity influenced by the weather?\n",
    "* How does the day of the week affect how active I am?\n",
    "* Am I more active on the weekends when I have more free time or does a structured weekday schedule have a greater effect?\n",
    "\n",
    "In order to answer these questions, data cannot just be extracted from my Apple Watch. In addition to csv files from my Apple Watch, I will utilize an open-source API to create a JSON file of the weather.\n",
    "\n",
    "Through this exploratory data analysis, I will be able to get a better understanding of just what influences my fitness habits. Information like this could help me improve my daily schedule to workout more effectively as well as find areas in my schedule where fitness could improve. Furthermore, a focused analysis such as this one could draw more general conclusions about how the workout mindset is influenced by both weather and times during the week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data\n",
    "\n",
    "In order to perform an extensive analysis of my Apple watch data, I need to gather data from various sources so that I can see what exactly influences my fitness activity and what trends I have created over the past semester. The following datasets will be loaded and cleaned for further analysis:\n",
    "\n",
    "1. Apple Daily Health data (12/26/2021 - 4/12/2022): csv file\n",
    "1. Apple Workout data (12/26/2021 - 4/12/2022): csv file\n",
    "1. MeteoStat Daily Weather data: JSON file\n",
    "1. Days of the Week data: created from `daily_health_data.csv`\n",
    "\n",
    "#### Loading the CSV Files\n",
    "\n",
    "The Apple Watch data needs to be uploaded into `Pandas` dataframes so that they can be properly cleaned for analysis. Since this will be the dataframe that the other data files will be surrounded around, the indexing will be done by date. This can be done with a few quick lines of code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Calories', 'Exercise Time (min)', 'Stand Hours', 'Flights Climbed',\n",
      "       'Heart Rate', 'Max Heart Rate', 'Avg Heart Rate', 'Rest Heart Rate',\n",
      "       'Step Count', 'Distance (mi) '],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "daily_health_df = pd.read_csv(\"daily_health_data.csv\", index_col=\"Date\")\n",
    "\n",
    "print(daily_health_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data from the above csv file was retrieved from an application on my iPhone called [Health Auto Export](https://apps.apple.com/us/app/health-auto-export-json-csv/id1115567069). Using an Apple shortcut, Health Auto Export was able to generate an extensive csv file of various health attributes. Each attribute listed above will be cleaned or deleted, depending on its relative performance. The below attributes are the ones that will be kept for further analysis.\n",
    "\n",
    "* **Calories**: total active calories burned (kcal)\n",
    "* **Exercise Time**: total exercise time (min)\n",
    "* **Flights Climbed**: total flights of stairs climbed\n",
    "* **Max Heart Rate**: highest heart rate reached (bpm)\n",
    "* **Avg Heart Rate**: average heart rate throughout day (bpm)\n",
    "* **Rest Heart Rate**: resting heart rate (bpm)\n",
    "* **Step Count**: total steps taken\n",
    "* **Distance**: total active distance covered (mi)\n",
    "  \n",
    "  \n",
    "  \n",
    "The next Apple Watch csv file is workout centered. This file includes data relating to specific workout instances. Date cannot be used as this file's index as there are multiple workouts logged under the same day. However, the start time of the workout is unique and can be used as the index for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Type', 'End', 'Duration', 'Total Energy (kcal)',\n",
      "       'Active Energy (kcal)', 'Max Heart Rate (bpm)', 'Avg Heart Rate (bpm)',\n",
      "       'Distance (mi)', 'Avg Speed(mi/hr)', 'Step Count (count)',\n",
      "       'Step Cadence (spm)', 'Swim Stroke Count (count)',\n",
      "       'Swim Stroke Cadence (spm)', 'Flights Climbed (count)',\n",
      "       'Elevation Ascended (ft)', 'Elevation Descended (ft)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "workout_df = pd.read_csv(\"workouts_data.csv\", index_col=\"Start\")\n",
    "\n",
    "print(workout_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workout data was also retrieved using the iPhone app [Health Auto Export](https://apps.apple.com/us/app/health-auto-export-json-csv/id1115567069). The Apple shortcut used to create this csv file did not allow for decisions to be made about which attributes to use. Therefore, half of these attributes will be used for data analysis. Below are the attributes that will be used for further analysis:\n",
    "\n",
    "* **Type**: type of workout completed\n",
    "* **Duration**: total time of workout (min)\n",
    "* **Total Energy**: total calories burned in workout (kcal)\n",
    "* **Max Heart Rate**: highest heart rate reached (bpm)\n",
    "* **Avg Heart Rate**: average workout heart rate\n",
    "\n",
    "#### Loading the JSON File\n",
    "\n",
    "The next data extraction that needs to be completed is the daily weather data for the city of Spokane over the course of this past semester. Found on RapidAPI's website, [MeteoStat's Daily Station API](https://rapidapi.com/meteostat/api/meteostat/) will be used to get a JSON file of the weather data for Spokane from 12/26/2021 - 4/12/2021.\n",
    "\n",
    "Using [MeteoStat's Station Finder](https://meteostat.net/en/place/us/spokane?t=2022-04-05/2022-04-12&s=KSFF0), Spokane's weather station can be used to create a JSON file with more detailed weather analysis. The code belows uses the above API to get the JSON file, parse through the necessary data, and write it to a `Pandas` dataframe for further analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            tavg  tmin  tmax   prcp  snow   wdir  wspd  wpgt    pres  tsun\n",
      "date                                                                      \n",
      "2021-12-26  28.2  25.0  32.0  0.043  None  244.0   5.4  None   997.4  None\n",
      "2021-12-27  19.4  14.0  25.0  0.024  None  281.0   4.9  None  1006.3  None\n",
      "2021-12-28  13.3   8.1  17.1  0.000  None  347.0   2.2  None  1010.2  None\n",
      "2021-12-29  13.1   8.1  17.1  0.000  None  324.0   4.2  None  1012.7  None\n",
      "2021-12-30  14.9  12.0  17.1  0.177  None    4.0   1.7  None  1006.3  None\n",
      "...          ...   ...   ...    ...   ...    ...   ...   ...     ...   ...\n",
      "2022-04-08  48.6  39.2  57.2  0.205  None  207.0  12.6  None  1016.0  None\n",
      "2022-04-09  40.8  32.0  50.0  0.047  None  228.0  11.7  None  1017.0  None\n",
      "2022-04-10  35.2  28.4  44.6  0.039  None  218.0   6.3  None  1012.2  None\n",
      "2022-04-11  35.2  28.4  41.0  0.020  None   53.0  11.9  None  1001.2  None\n",
      "2022-04-12  36.9  32.0  42.8  0.020  None   59.0  11.1  None  1013.5  None\n",
      "\n",
      "[108 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "weather_url = \"https://meteostat.p.rapidapi.com/stations/daily\"\n",
    "\n",
    "weather_key = \"48c6248dd3msh5bf7b8a377bd25cp19e73ajsn114ccda534b5\"\n",
    "weather_headers = {\"x-rapidapi-key\": weather_key}\n",
    "weather_query = {\"station\": \"KSFF0\", \"start\": \"2021-12-26\", \"end\": \"2022-04-12\", \"units\": \"imperial\"}\n",
    "\n",
    "weather_response = requests.get(url=weather_url, headers=weather_headers, params=weather_query)\n",
    "\n",
    "# Parse through json object and storel data in dataframe for return\n",
    "weather_json_obj = json.loads(weather_response.text)\n",
    "weather_data_list = weather_json_obj[\"data\"]\n",
    "\n",
    "daily_weather_df = pd.DataFrame(weather_data_list)\n",
    "daily_weather_df.set_index(\"date\", inplace=True)\n",
    "\n",
    "print(daily_weather_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to compare weather data with health data, the date will be used as the index for clarity. This JSON file provides extensive information about the daily weather; however, some of these attributes do not apply to the cross-analysis with the Apple Watch data. The below attributes will be kept and cleaned for future analysis:\n",
    "\n",
    "* **tavg**: average temperature (Fahrenheit)\n",
    "* **tmin**: lowest temperature of the day (Fahrenheit)\n",
    "* **tmax**: highest temperature of the day (Fahrenheit)\n",
    "* **prcp**: total precipitation (in)\n",
    "* **wspd**: average wind speed (mi/hr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the Days of the Week Dataframe\n",
    "\n",
    "The Days of the Week file is important in weekend v. weekday analysis. In order to create a `Pandas` dataframe of this information, the timestamp of each day and days of week need to be added to an empty dataframe. [GeeksForGeeks](https://www.geeksforgeeks.org/python-pandas-date_range-method/#:~:text=date_range()%20is%20one%20of,return%20a%20fixed%20frequency%20DatetimeIndex.&text=Parameters%3A,Right%20bound%20for%20generating%20dates.) and [Stack Overflow](https://stackoverflow.com/questions/30222533/create-a-day-of-week-column-in-a-pandas-dataframe-using-python) were used to create this dataframe from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Day of Week\n",
      "Date                  \n",
      "2021-12-26      Sunday\n",
      "2021-12-27      Monday\n",
      "2021-12-28     Tuesday\n",
      "2021-12-29   Wednesday\n",
      "2021-12-30    Thursday\n",
      "...                ...\n",
      "2022-04-08      Friday\n",
      "2022-04-09    Saturday\n",
      "2022-04-10      Sunday\n",
      "2022-04-11      Monday\n",
      "2022-04-12     Tuesday\n",
      "\n",
      "[108 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "days_of_week_df = pd.DataFrame()\n",
    "\n",
    "days_of_week_df[\"Date\"] = pd.Series(pd.date_range('2021-12-26', '2022-04-12', freq='D'))\n",
    "days_of_week_df[\"Day of Week\"] = days_of_week_df[\"Date\"].dt.day_name()\n",
    "\n",
    "days_of_week_df.set_index(\"Date\", inplace=True)\n",
    "\n",
    "print(days_of_week_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "\n",
    "Now that all of the necessary data has been loaded into dataframes, the data analysis can proceed. After each dataframe has been combed through for missing values, the cleaned sets can then be visualized, joined, and compared. The next part will take the following steps to get a better grasps of relations among the dataframes:\n",
    "\n",
    "1. Data Cleaning\n",
    "1. Data Aggregation\n",
    "1. Data Visualization\n",
    "1. Hypothesis Testing\n",
    "\n",
    "### Data Cleaning\n",
    "\n",
    "As mentioned in the introduction, some of the datasets have unnecessary attributes that clutter the dataset and missing values that need to be filled. This needs to be taken care of before the data can be joined and compared.\n",
    "\n",
    "#### Daily Health Dataframe\n",
    "\n",
    "This dataset will delete the following attribute columns due to irrelevance or lack of data points for further analysis:\n",
    "\n",
    "* Heart Rate\n",
    "* Stand Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Calories', 'Exercise Time (min)', 'Flights Climbed', 'Max Heart Rate',\n",
      "       'Avg Heart Rate', 'Rest Heart Rate', 'Step Count', 'Distance (mi) '],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "daily_health_df.drop(\"Heart Rate\", axis=1, inplace=True)\n",
    "daily_health_df.drop(\"Stand Hours\", axis=1, inplace=True)\n",
    "\n",
    "print(daily_health_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the unnecessary columns have been deleted, missing values need to be filled. After looking at the data, a couple of different types of data fills will be used. For this dataframe, the following attributes will use this type of fill:\n",
    "\n",
    "1. **Exercise Time**: fill with `0` since not enough exercise was completed to log\n",
    "1. **Flights Climbed**: fill with `0` as days without enough elevation gain did not register a flight climbed\n",
    "1. **Rest Heart Rate**: fill with `daily_health_df[\"Rest Heart Rate\"].mean()` as middle value since only few days are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null value column 0 count: 0\n",
      "Null value column 1 count: 0\n",
      "Null value column 2 count: 0\n",
      "Null value column 3 count: 0\n",
      "Null value column 4 count: 0\n",
      "Null value column 5 count: 0\n",
      "Null value column 6 count: 0\n",
      "Null value column 7 count: 0\n"
     ]
    }
   ],
   "source": [
    "daily_health_df[\"Exercise Time (min)\"].fillna(0, inplace=True)\n",
    "daily_health_df[\"Flights Climbed\"].fillna(0, inplace=True)\n",
    "\n",
    "rest_avg = daily_health_df[\"Rest Heart Rate\"].mean()\n",
    "daily_health_df[\"Rest Heart Rate\"].fillna(rest_avg, inplace=True)\n",
    "\n",
    "for i in range(len(daily_health_df.columns)):\n",
    "    print(\"Null value column\", i, \"count:\", daily_health_df.iloc[i].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workout Dataframe\n",
    "\n",
    "The only cleaning that needs to be completed for the workout dataframe is deletion of columns with non-essential data. Some other columns lack enough data points to be used for statistical analysis. Therefore, the following attributes will be removed from this dataframe:\n",
    "\n",
    "* End\n",
    "* Active Energy (kcal)\n",
    "* Distance (mi)\n",
    "* Avg Speed (mi/hr)\n",
    "* Step Count (count)\n",
    "* Step Cadence (spm)\n",
    "* Swim Stroke Count (count)\n",
    "* Swim Stroke Cadence (count)\n",
    "* Flights Climbed (count)\n",
    "* Elevation Ascended (ft)\n",
    "* Elevation Descended (ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Type', 'Duration', 'Total Energy (kcal)', 'Max Heart Rate (bpm)',\n",
      "       'Avg Heart Rate (bpm)'],\n",
      "      dtype='object')\n",
      "Null value column 0 count: 0\n",
      "Null value column 1 count: 0\n",
      "Null value column 2 count: 0\n",
      "Null value column 3 count: 0\n",
      "Null value column 4 count: 0\n"
     ]
    }
   ],
   "source": [
    "workout_df.drop(\"End\", axis=1, inplace=True)\n",
    "workout_df.drop(\"Active Energy (kcal)\", axis=1, inplace=True)\n",
    "workout_df.drop(\"Distance (mi)\", axis=1, inplace=True)\n",
    "workout_df.drop(\"Avg Speed(mi/hr)\", axis=1, inplace=True)\n",
    "workout_df.drop(\"Step Count (count)\", axis=1, inplace=True)\n",
    "workout_df.drop(\"Step Cadence (spm)\", axis=1, inplace=True)\n",
    "workout_df.drop(\"Swim Stroke Count (count)\", axis=1, inplace=True)\n",
    "workout_df.drop(\"Swim Stroke Cadence (spm)\", axis=1, inplace=True)\n",
    "workout_df.drop(\"Flights Climbed (count)\", axis=1, inplace=True)\n",
    "workout_df.drop(\"Elevation Ascended (ft)\", axis=1, inplace=True)\n",
    "workout_df.drop(\"Elevation Descended (ft)\", axis=1, inplace=True)\n",
    "\n",
    "print(workout_df.columns)\n",
    "for i in range(len(workout_df.columns)):\n",
    "    print(\"Null value column\", i, \"count:\", workout_df.iloc[i].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Daily Weather Dataframe\n",
    "\n",
    "Similar to the workout dataframe there is little work that needs to be done in order to prepare it for statistical analysis. There are a few columns that do not have necessary information for visualization, so the following attributes will be removed from the dataframe:\n",
    "\n",
    "* snow (snow fallen)\n",
    "* wdir (wind direction)\n",
    "* wpgt (peak wind gust)\n",
    "* pres (sea-level air pressure)\n",
    "* tsun (sunshine total in min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['tavg', 'tmin', 'tmax', 'prcp', 'wspd'], dtype='object')\n",
      "Null value column 0 count: 0\n",
      "Null value column 1 count: 0\n",
      "Null value column 2 count: 0\n",
      "Null value column 3 count: 0\n",
      "Null value column 4 count: 0\n"
     ]
    }
   ],
   "source": [
    "daily_weather_df.drop(\"snow\", axis=1, inplace=True)\n",
    "daily_weather_df.drop(\"wdir\", axis=1, inplace=True)\n",
    "daily_weather_df.drop(\"wpgt\", axis=1, inplace=True)\n",
    "daily_weather_df.drop(\"pres\", axis=1, inplace=True)\n",
    "daily_weather_df.drop(\"tsun\", axis=1, inplace=True)\n",
    "\n",
    "print(daily_weather_df.columns)\n",
    "for i in range(len(daily_weather_df.columns)):\n",
    "    print(\"Null value column\", i, \"count:\", daily_weather_df.iloc[i].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Aggregation\n",
    "\n",
    "In order to properly find trends to visualize and test on, the cleaned dataframes need to be joined and organized by specific attributes. First, the daily health dataframe needs to be joined with the daily weather dataframe. Additionally, the days of the week dataframe needs to be joined with both the daily health and workout dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "10a6e54dcf7cd4a6e4c60a02b2c0aedf793edece3f95e71af56e4832a6f99a52"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
